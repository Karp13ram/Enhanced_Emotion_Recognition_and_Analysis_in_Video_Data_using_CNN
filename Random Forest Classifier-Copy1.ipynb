{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.feature_selection import chi2, SelectKBest, SelectFdr, SelectFwe\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "#Facial Id, NoseX, NoseY, ChinX, ChinY, LEX, LER, REX, RER, LMX, LMY, RMX, RMY, Yaw, Pitch, Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data = \"F:/Video_Interview_Bots/Video_Interview_Bot/new_data/Emotion_only - Sheet1 (2).csv\"\n",
    "# y_data = \"F:/Video_Interview_Bots/Video_Interview_Bot/new_data/y-output - Sheet1.csv\"\n",
    "# data = \"F:/Video_Interview_Bots/Video_Interview_Bot/new_data/Emotion_only - Sheet1.csv\"\n",
    "x_data = \"F:/Video_Interview_Bots/Video_Interview_Bot/new_data/three_features_merged.csv\"\n",
    "y_data = \"F:/Video_Interview_Bots/Video_Interview_Bot/new_data/y-output - Sheet1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.297315623</th>\n",
       "      <th>5.10622414</th>\n",
       "      <th>5.33300425</th>\n",
       "      <th>5.541379781</th>\n",
       "      <th>5.043890154</th>\n",
       "      <th>5.866118592</th>\n",
       "      <th>3.57615974</th>\n",
       "      <th>4.865589795</th>\n",
       "      <th>3.771664731</th>\n",
       "      <th>5.25478356</th>\n",
       "      <th>5.800467905</th>\n",
       "      <th>5.147909377</th>\n",
       "      <th>4.891580046</th>\n",
       "      <th>5.351075433</th>\n",
       "      <th>5.350759594</th>\n",
       "      <th>5.845226374</th>\n",
       "      <th>5.610512744</th>\n",
       "      <th>5.477533668</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.110904</td>\n",
       "      <td>4.919812</td>\n",
       "      <td>5.055394</td>\n",
       "      <td>5.273727</td>\n",
       "      <td>4.571966</td>\n",
       "      <td>5.674185</td>\n",
       "      <td>5.816090</td>\n",
       "      <td>4.977200</td>\n",
       "      <td>5.122170</td>\n",
       "      <td>5.399408</td>\n",
       "      <td>5.796841</td>\n",
       "      <td>4.204577</td>\n",
       "      <td>4.641287</td>\n",
       "      <td>5.649944</td>\n",
       "      <td>5.517449</td>\n",
       "      <td>5.609754</td>\n",
       "      <td>5.933670</td>\n",
       "      <td>4.947802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5.649863</td>\n",
       "      <td>5.475563</td>\n",
       "      <td>5.302991</td>\n",
       "      <td>5.850965</td>\n",
       "      <td>5.122306</td>\n",
       "      <td>5.611396</td>\n",
       "      <td>6.402927</td>\n",
       "      <td>4.821191</td>\n",
       "      <td>4.389287</td>\n",
       "      <td>6.137911</td>\n",
       "      <td>6.020754</td>\n",
       "      <td>5.387709</td>\n",
       "      <td>4.929066</td>\n",
       "      <td>5.313748</td>\n",
       "      <td>5.488048</td>\n",
       "      <td>5.913916</td>\n",
       "      <td>5.875073</td>\n",
       "      <td>4.876444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3.770640</td>\n",
       "      <td>3.788818</td>\n",
       "      <td>3.778396</td>\n",
       "      <td>3.834715</td>\n",
       "      <td>3.125481</td>\n",
       "      <td>4.512165</td>\n",
       "      <td>4.104517</td>\n",
       "      <td>3.287912</td>\n",
       "      <td>3.816509</td>\n",
       "      <td>4.013969</td>\n",
       "      <td>6.075620</td>\n",
       "      <td>2.574769</td>\n",
       "      <td>4.039454</td>\n",
       "      <td>6.104773</td>\n",
       "      <td>6.038526</td>\n",
       "      <td>4.260712</td>\n",
       "      <td>5.285248</td>\n",
       "      <td>3.868875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.862214</td>\n",
       "      <td>3.560751</td>\n",
       "      <td>3.887543</td>\n",
       "      <td>4.701943</td>\n",
       "      <td>3.171457</td>\n",
       "      <td>5.222559</td>\n",
       "      <td>4.912748</td>\n",
       "      <td>4.644977</td>\n",
       "      <td>3.442679</td>\n",
       "      <td>4.771715</td>\n",
       "      <td>5.496765</td>\n",
       "      <td>3.615313</td>\n",
       "      <td>3.416008</td>\n",
       "      <td>5.383760</td>\n",
       "      <td>5.205279</td>\n",
       "      <td>4.882403</td>\n",
       "      <td>5.889864</td>\n",
       "      <td>3.564973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.200001</td>\n",
       "      <td>4.746082</td>\n",
       "      <td>4.988738</td>\n",
       "      <td>5.622451</td>\n",
       "      <td>4.340798</td>\n",
       "      <td>5.097418</td>\n",
       "      <td>4.101780</td>\n",
       "      <td>4.552763</td>\n",
       "      <td>4.577794</td>\n",
       "      <td>4.631133</td>\n",
       "      <td>5.377186</td>\n",
       "      <td>4.707302</td>\n",
       "      <td>5.359631</td>\n",
       "      <td>5.551020</td>\n",
       "      <td>5.937585</td>\n",
       "      <td>5.932348</td>\n",
       "      <td>5.836909</td>\n",
       "      <td>4.744369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5.109074</td>\n",
       "      <td>4.889102</td>\n",
       "      <td>4.795988</td>\n",
       "      <td>5.550820</td>\n",
       "      <td>4.833639</td>\n",
       "      <td>5.859717</td>\n",
       "      <td>4.328272</td>\n",
       "      <td>4.034151</td>\n",
       "      <td>5.476115</td>\n",
       "      <td>5.087372</td>\n",
       "      <td>4.855716</td>\n",
       "      <td>4.635599</td>\n",
       "      <td>3.602517</td>\n",
       "      <td>5.999890</td>\n",
       "      <td>5.912265</td>\n",
       "      <td>6.046410</td>\n",
       "      <td>6.179469</td>\n",
       "      <td>5.226973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.236546</td>\n",
       "      <td>3.844694</td>\n",
       "      <td>4.702535</td>\n",
       "      <td>4.481112</td>\n",
       "      <td>4.001915</td>\n",
       "      <td>4.631655</td>\n",
       "      <td>4.653617</td>\n",
       "      <td>4.892098</td>\n",
       "      <td>3.755251</td>\n",
       "      <td>4.804046</td>\n",
       "      <td>5.739944</td>\n",
       "      <td>3.894828</td>\n",
       "      <td>3.725696</td>\n",
       "      <td>5.301356</td>\n",
       "      <td>5.188286</td>\n",
       "      <td>5.101746</td>\n",
       "      <td>5.137301</td>\n",
       "      <td>4.323285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.414892</td>\n",
       "      <td>4.433070</td>\n",
       "      <td>5.010430</td>\n",
       "      <td>5.616076</td>\n",
       "      <td>5.601586</td>\n",
       "      <td>5.426861</td>\n",
       "      <td>6.062173</td>\n",
       "      <td>5.016286</td>\n",
       "      <td>3.332458</td>\n",
       "      <td>6.500329</td>\n",
       "      <td>4.791550</td>\n",
       "      <td>5.621231</td>\n",
       "      <td>3.912199</td>\n",
       "      <td>4.476537</td>\n",
       "      <td>5.521215</td>\n",
       "      <td>5.549829</td>\n",
       "      <td>6.014960</td>\n",
       "      <td>4.923550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5.895206</td>\n",
       "      <td>5.952686</td>\n",
       "      <td>5.662050</td>\n",
       "      <td>5.573416</td>\n",
       "      <td>4.952103</td>\n",
       "      <td>5.876603</td>\n",
       "      <td>6.248633</td>\n",
       "      <td>4.811490</td>\n",
       "      <td>6.248145</td>\n",
       "      <td>5.354862</td>\n",
       "      <td>6.226922</td>\n",
       "      <td>5.328155</td>\n",
       "      <td>5.534318</td>\n",
       "      <td>6.654135</td>\n",
       "      <td>6.487857</td>\n",
       "      <td>6.168383</td>\n",
       "      <td>5.922735</td>\n",
       "      <td>6.436036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3.888033</td>\n",
       "      <td>3.414412</td>\n",
       "      <td>3.767839</td>\n",
       "      <td>3.722152</td>\n",
       "      <td>2.947855</td>\n",
       "      <td>4.592380</td>\n",
       "      <td>5.206461</td>\n",
       "      <td>4.220129</td>\n",
       "      <td>4.226282</td>\n",
       "      <td>4.410603</td>\n",
       "      <td>5.357684</td>\n",
       "      <td>3.029517</td>\n",
       "      <td>3.705172</td>\n",
       "      <td>5.205815</td>\n",
       "      <td>5.220754</td>\n",
       "      <td>4.649341</td>\n",
       "      <td>4.896577</td>\n",
       "      <td>4.660617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     5.297315623  5.10622414  5.33300425  5.541379781  5.043890154  \\\n",
       "56      5.110904    4.919812    5.055394     5.273727     4.571966   \n",
       "82      5.649863    5.475563    5.302991     5.850965     5.122306   \n",
       "51      3.770640    3.788818    3.778396     3.834715     3.125481   \n",
       "32      3.862214    3.560751    3.887543     4.701943     3.171457   \n",
       "19      5.200001    4.746082    4.988738     5.622451     4.340798   \n",
       "..           ...         ...         ...          ...          ...   \n",
       "103     5.109074    4.889102    4.795988     5.550820     4.833639   \n",
       "14      4.236546    3.844694    4.702535     4.481112     4.001915   \n",
       "0       4.414892    4.433070    5.010430     5.616076     5.601586   \n",
       "57      5.895206    5.952686    5.662050     5.573416     4.952103   \n",
       "102     3.888033    3.414412    3.767839     3.722152     2.947855   \n",
       "\n",
       "     5.866118592  3.57615974  4.865589795  3.771664731  5.25478356  \\\n",
       "56      5.674185    5.816090     4.977200     5.122170    5.399408   \n",
       "82      5.611396    6.402927     4.821191     4.389287    6.137911   \n",
       "51      4.512165    4.104517     3.287912     3.816509    4.013969   \n",
       "32      5.222559    4.912748     4.644977     3.442679    4.771715   \n",
       "19      5.097418    4.101780     4.552763     4.577794    4.631133   \n",
       "..           ...         ...          ...          ...         ...   \n",
       "103     5.859717    4.328272     4.034151     5.476115    5.087372   \n",
       "14      4.631655    4.653617     4.892098     3.755251    4.804046   \n",
       "0       5.426861    6.062173     5.016286     3.332458    6.500329   \n",
       "57      5.876603    6.248633     4.811490     6.248145    5.354862   \n",
       "102     4.592380    5.206461     4.220129     4.226282    4.410603   \n",
       "\n",
       "     5.800467905  5.147909377  4.891580046  5.351075433  5.350759594  \\\n",
       "56      5.796841     4.204577     4.641287     5.649944     5.517449   \n",
       "82      6.020754     5.387709     4.929066     5.313748     5.488048   \n",
       "51      6.075620     2.574769     4.039454     6.104773     6.038526   \n",
       "32      5.496765     3.615313     3.416008     5.383760     5.205279   \n",
       "19      5.377186     4.707302     5.359631     5.551020     5.937585   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "103     4.855716     4.635599     3.602517     5.999890     5.912265   \n",
       "14      5.739944     3.894828     3.725696     5.301356     5.188286   \n",
       "0       4.791550     5.621231     3.912199     4.476537     5.521215   \n",
       "57      6.226922     5.328155     5.534318     6.654135     6.487857   \n",
       "102     5.357684     3.029517     3.705172     5.205815     5.220754   \n",
       "\n",
       "     5.845226374  5.610512744  5.477533668  \n",
       "56      5.609754     5.933670     4.947802  \n",
       "82      5.913916     5.875073     4.876444  \n",
       "51      4.260712     5.285248     3.868875  \n",
       "32      4.882403     5.889864     3.564973  \n",
       "19      5.932348     5.836909     4.744369  \n",
       "..           ...          ...          ...  \n",
       "103     6.046410     6.179469     5.226973  \n",
       "14      5.101746     5.137301     4.323285  \n",
       "0       5.549829     6.014960     4.923550  \n",
       "57      6.168383     5.922735     6.436036  \n",
       "102     4.649341     4.896577     4.660617  \n",
       "\n",
       "[137 rows x 18 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = pd.read_csv(x_data)\n",
    "y_df = pd.read_csv(y_data)\n",
    "# df = pd.read_csv(data)\n",
    "\n",
    "y_df = y_df.astype(float, errors='ignore')\n",
    "x_df = x_df.drop(x_df.columns[0], axis=1)\n",
    "y_df = y_df.drop(y_df.columns[0], axis=1)\n",
    "y_df = y_df.drop(y_df.columns[-1], axis=1)\n",
    "x_df = x_df.abs()\n",
    "df = pd.concat([x_df,y_df],axis =1)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "x_df = df.iloc[:,:99]\n",
    "y_df = df.iloc[:,99:]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>5.297315623</th>\n",
       "      <th>5.10622414</th>\n",
       "      <th>5.33300425</th>\n",
       "      <th>5.541379781</th>\n",
       "      <th>5.043890154</th>\n",
       "      <th>5.866118592</th>\n",
       "      <th>3.57615974</th>\n",
       "      <th>4.865589795</th>\n",
       "      <th>3.771664731</th>\n",
       "      <th>5.25478356</th>\n",
       "      <th>5.800467905</th>\n",
       "      <th>5.147909377</th>\n",
       "      <th>4.891580046</th>\n",
       "      <th>5.351075433</th>\n",
       "      <th>5.350759594</th>\n",
       "      <th>5.845226374</th>\n",
       "      <th>5.610512744</th>\n",
       "      <th>5.477533668</th>\n",
       "      <th>93.13119551</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P83</td>\n",
       "      <td>5.846003</td>\n",
       "      <td>5.537189</td>\n",
       "      <td>6.085046</td>\n",
       "      <td>5.884720</td>\n",
       "      <td>6.072378</td>\n",
       "      <td>5.745279</td>\n",
       "      <td>6.543444</td>\n",
       "      <td>4.924798</td>\n",
       "      <td>4.418327</td>\n",
       "      <td>6.562634</td>\n",
       "      <td>6.309847</td>\n",
       "      <td>5.912896</td>\n",
       "      <td>5.372444</td>\n",
       "      <td>5.304540</td>\n",
       "      <td>5.847669</td>\n",
       "      <td>5.919812</td>\n",
       "      <td>6.384817</td>\n",
       "      <td>5.740260</td>\n",
       "      <td>104.412104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P86</td>\n",
       "      <td>4.474839</td>\n",
       "      <td>3.959260</td>\n",
       "      <td>4.789071</td>\n",
       "      <td>5.535814</td>\n",
       "      <td>5.245841</td>\n",
       "      <td>5.497855</td>\n",
       "      <td>5.941442</td>\n",
       "      <td>4.921526</td>\n",
       "      <td>3.763968</td>\n",
       "      <td>6.095773</td>\n",
       "      <td>5.654321</td>\n",
       "      <td>5.356061</td>\n",
       "      <td>3.249204</td>\n",
       "      <td>5.228986</td>\n",
       "      <td>5.294805</td>\n",
       "      <td>5.004189</td>\n",
       "      <td>6.098644</td>\n",
       "      <td>4.933040</td>\n",
       "      <td>91.044639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P25</td>\n",
       "      <td>5.016637</td>\n",
       "      <td>4.867697</td>\n",
       "      <td>5.226313</td>\n",
       "      <td>5.237507</td>\n",
       "      <td>5.041119</td>\n",
       "      <td>4.364811</td>\n",
       "      <td>5.298784</td>\n",
       "      <td>4.417650</td>\n",
       "      <td>2.658715</td>\n",
       "      <td>5.262436</td>\n",
       "      <td>5.649894</td>\n",
       "      <td>4.709428</td>\n",
       "      <td>4.650149</td>\n",
       "      <td>5.007264</td>\n",
       "      <td>5.208024</td>\n",
       "      <td>5.515620</td>\n",
       "      <td>5.922735</td>\n",
       "      <td>4.103720</td>\n",
       "      <td>88.158501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P5</td>\n",
       "      <td>5.457670</td>\n",
       "      <td>5.571558</td>\n",
       "      <td>5.772488</td>\n",
       "      <td>5.903057</td>\n",
       "      <td>4.707062</td>\n",
       "      <td>6.694276</td>\n",
       "      <td>3.920479</td>\n",
       "      <td>4.927181</td>\n",
       "      <td>5.881741</td>\n",
       "      <td>5.649119</td>\n",
       "      <td>5.886326</td>\n",
       "      <td>4.695523</td>\n",
       "      <td>5.582514</td>\n",
       "      <td>6.130488</td>\n",
       "      <td>5.916373</td>\n",
       "      <td>6.322086</td>\n",
       "      <td>6.020070</td>\n",
       "      <td>5.629838</td>\n",
       "      <td>100.667850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P60</td>\n",
       "      <td>4.865379</td>\n",
       "      <td>4.831596</td>\n",
       "      <td>5.169776</td>\n",
       "      <td>5.728488</td>\n",
       "      <td>5.419990</td>\n",
       "      <td>3.328188</td>\n",
       "      <td>5.825523</td>\n",
       "      <td>4.610968</td>\n",
       "      <td>3.554746</td>\n",
       "      <td>6.099715</td>\n",
       "      <td>5.227083</td>\n",
       "      <td>5.409835</td>\n",
       "      <td>4.071194</td>\n",
       "      <td>4.484927</td>\n",
       "      <td>4.902280</td>\n",
       "      <td>5.479518</td>\n",
       "      <td>5.996484</td>\n",
       "      <td>4.418762</td>\n",
       "      <td>89.424453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>PP72</td>\n",
       "      <td>5.175140</td>\n",
       "      <td>5.348370</td>\n",
       "      <td>5.321074</td>\n",
       "      <td>5.836417</td>\n",
       "      <td>5.408563</td>\n",
       "      <td>4.892950</td>\n",
       "      <td>5.052155</td>\n",
       "      <td>5.084078</td>\n",
       "      <td>3.749294</td>\n",
       "      <td>5.471829</td>\n",
       "      <td>5.912104</td>\n",
       "      <td>5.110310</td>\n",
       "      <td>5.670881</td>\n",
       "      <td>5.713355</td>\n",
       "      <td>5.370412</td>\n",
       "      <td>6.137125</td>\n",
       "      <td>6.256265</td>\n",
       "      <td>4.892500</td>\n",
       "      <td>96.402824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>PP37</td>\n",
       "      <td>5.709428</td>\n",
       "      <td>5.334367</td>\n",
       "      <td>5.705593</td>\n",
       "      <td>5.760110</td>\n",
       "      <td>5.414534</td>\n",
       "      <td>5.809710</td>\n",
       "      <td>5.821436</td>\n",
       "      <td>5.097783</td>\n",
       "      <td>5.009161</td>\n",
       "      <td>6.088443</td>\n",
       "      <td>6.045007</td>\n",
       "      <td>5.724422</td>\n",
       "      <td>5.397243</td>\n",
       "      <td>5.152825</td>\n",
       "      <td>5.335149</td>\n",
       "      <td>5.947025</td>\n",
       "      <td>6.197242</td>\n",
       "      <td>5.600249</td>\n",
       "      <td>101.149726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>P3</td>\n",
       "      <td>4.414892</td>\n",
       "      <td>4.433070</td>\n",
       "      <td>5.010430</td>\n",
       "      <td>5.616076</td>\n",
       "      <td>5.601586</td>\n",
       "      <td>5.426861</td>\n",
       "      <td>6.062173</td>\n",
       "      <td>5.016286</td>\n",
       "      <td>3.332458</td>\n",
       "      <td>6.500329</td>\n",
       "      <td>4.791550</td>\n",
       "      <td>5.621231</td>\n",
       "      <td>3.912199</td>\n",
       "      <td>4.476537</td>\n",
       "      <td>5.521215</td>\n",
       "      <td>5.549829</td>\n",
       "      <td>6.014960</td>\n",
       "      <td>4.923550</td>\n",
       "      <td>92.225232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>PP6</td>\n",
       "      <td>4.139805</td>\n",
       "      <td>3.892621</td>\n",
       "      <td>3.548270</td>\n",
       "      <td>4.376918</td>\n",
       "      <td>3.388857</td>\n",
       "      <td>4.279989</td>\n",
       "      <td>2.682460</td>\n",
       "      <td>4.245647</td>\n",
       "      <td>3.555086</td>\n",
       "      <td>3.394588</td>\n",
       "      <td>4.435251</td>\n",
       "      <td>2.342349</td>\n",
       "      <td>4.398971</td>\n",
       "      <td>5.280238</td>\n",
       "      <td>5.222330</td>\n",
       "      <td>5.454540</td>\n",
       "      <td>4.905344</td>\n",
       "      <td>4.168653</td>\n",
       "      <td>73.711914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>P66</td>\n",
       "      <td>5.517477</td>\n",
       "      <td>5.822855</td>\n",
       "      <td>4.899567</td>\n",
       "      <td>6.193300</td>\n",
       "      <td>6.214157</td>\n",
       "      <td>5.731098</td>\n",
       "      <td>5.843519</td>\n",
       "      <td>5.483857</td>\n",
       "      <td>2.520177</td>\n",
       "      <td>5.609375</td>\n",
       "      <td>4.945086</td>\n",
       "      <td>5.022278</td>\n",
       "      <td>4.515410</td>\n",
       "      <td>5.479875</td>\n",
       "      <td>5.696727</td>\n",
       "      <td>5.311579</td>\n",
       "      <td>5.539019</td>\n",
       "      <td>5.567501</td>\n",
       "      <td>95.912855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       P1  5.297315623  5.10622414  5.33300425  5.541379781  5.043890154  \\\n",
       "0     P83     5.846003    5.537189    6.085046     5.884720     6.072378   \n",
       "1     P86     4.474839    3.959260    4.789071     5.535814     5.245841   \n",
       "2     P25     5.016637    4.867697    5.226313     5.237507     5.041119   \n",
       "3      P5     5.457670    5.571558    5.772488     5.903057     4.707062   \n",
       "4     P60     4.865379    4.831596    5.169776     5.728488     5.419990   \n",
       "..    ...          ...         ...         ...          ...          ...   \n",
       "132  PP72     5.175140    5.348370    5.321074     5.836417     5.408563   \n",
       "133  PP37     5.709428    5.334367    5.705593     5.760110     5.414534   \n",
       "134    P3     4.414892    4.433070    5.010430     5.616076     5.601586   \n",
       "135   PP6     4.139805    3.892621    3.548270     4.376918     3.388857   \n",
       "136   P66     5.517477    5.822855    4.899567     6.193300     6.214157   \n",
       "\n",
       "     5.866118592  3.57615974  4.865589795  3.771664731  5.25478356  \\\n",
       "0       5.745279    6.543444     4.924798     4.418327    6.562634   \n",
       "1       5.497855    5.941442     4.921526     3.763968    6.095773   \n",
       "2       4.364811    5.298784     4.417650     2.658715    5.262436   \n",
       "3       6.694276    3.920479     4.927181     5.881741    5.649119   \n",
       "4       3.328188    5.825523     4.610968     3.554746    6.099715   \n",
       "..           ...         ...          ...          ...         ...   \n",
       "132     4.892950    5.052155     5.084078     3.749294    5.471829   \n",
       "133     5.809710    5.821436     5.097783     5.009161    6.088443   \n",
       "134     5.426861    6.062173     5.016286     3.332458    6.500329   \n",
       "135     4.279989    2.682460     4.245647     3.555086    3.394588   \n",
       "136     5.731098    5.843519     5.483857     2.520177    5.609375   \n",
       "\n",
       "     5.800467905  5.147909377  4.891580046  5.351075433  5.350759594  \\\n",
       "0       6.309847     5.912896     5.372444     5.304540     5.847669   \n",
       "1       5.654321     5.356061     3.249204     5.228986     5.294805   \n",
       "2       5.649894     4.709428     4.650149     5.007264     5.208024   \n",
       "3       5.886326     4.695523     5.582514     6.130488     5.916373   \n",
       "4       5.227083     5.409835     4.071194     4.484927     4.902280   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "132     5.912104     5.110310     5.670881     5.713355     5.370412   \n",
       "133     6.045007     5.724422     5.397243     5.152825     5.335149   \n",
       "134     4.791550     5.621231     3.912199     4.476537     5.521215   \n",
       "135     4.435251     2.342349     4.398971     5.280238     5.222330   \n",
       "136     4.945086     5.022278     4.515410     5.479875     5.696727   \n",
       "\n",
       "     5.845226374  5.610512744  5.477533668  93.13119551  \n",
       "0       5.919812     6.384817     5.740260   104.412104  \n",
       "1       5.004189     6.098644     4.933040    91.044639  \n",
       "2       5.515620     5.922735     4.103720    88.158501  \n",
       "3       6.322086     6.020070     5.629838   100.667850  \n",
       "4       5.479518     5.996484     4.418762    89.424453  \n",
       "..           ...          ...          ...          ...  \n",
       "132     6.137125     6.256265     4.892500    96.402824  \n",
       "133     5.947025     6.197242     5.600249   101.149726  \n",
       "134     5.549829     6.014960     4.923550    92.225232  \n",
       "135     5.454540     4.905344     4.168653    73.711914  \n",
       "136     5.311579     5.539019     5.567501    95.912855  \n",
       "\n",
       "[137 rows x 20 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "x_df = pd.read_csv(x_data)\n",
    "y_df = pd.read_csv(y_data)\n",
    "\n",
    "# Convert y_df to float, ignore errors for non-numeric columns\n",
    "y_df = y_df.astype(float, errors='ignore')\n",
    "\n",
    "# Drop the first and last columns of y_df if needed, else remove these lines\n",
    "# Ensure all columns are retained, so only drop if you actually need to\n",
    "# y_df = y_df.drop(y_df.columns[0], axis=1)\n",
    "# y_df = y_df.drop(y_df.columns[-1], axis=1)\n",
    "\n",
    "# Get the absolute values for x_df, assuming that’s needed for your analysis\n",
    "# x_df = x_df.abs()\n",
    "\n",
    "# Concatenate x_df and y_df along columns (axis=1)\n",
    "df = pd.concat([x_df, y_df], axis=1)\n",
    "\n",
    "# Randomly shuffle the rows of the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Assign x_df and y_df based on the original dimensions\n",
    "# Assuming x_df originally had 99 columns and the remaining belong to y_df\n",
    "x_df = df.iloc[:, :x_df.shape[1]]\n",
    "y_df = df.iloc[:, x_df.shape[1]:]  # The remaining columns for y_df\n",
    "\n",
    "# Display the modified y_df\n",
    "y_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clf = RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=8, criterion='gini')\n",
    "# efs1 = EFS(clf, \n",
    "#            min_features=1,\n",
    "#            max_features=10,\n",
    "#            scoring='accuracy',\n",
    "#            print_progress=True,\n",
    "#            cv=5)\n",
    "\n",
    "\n",
    "# efs1 = efs1.fit(X_train, y_train[y_train.columns[0:1]])\n",
    "# print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "    \n",
    "from sklearn import preprocessing\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"weighted\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (108, 2)\n",
      "Shape of y_train for target 4.414892172: (108,)\n",
      "First few values of y_train_target for target 4.414892172: 49    5.836774\n",
      "44    4.719198\n",
      "86    5.022670\n",
      "89    3.716696\n",
      "39    6.580971\n",
      "Name: 4.414892172, dtype: float64\n",
      "R^2 score for target 4.414892172: -0.23825534288285222\n",
      "Shape of X_train: (108, 1)\n",
      "Shape of y_train for target 4.4330699: (108,)\n",
      "First few values of y_train_target for target 4.4330699: 49    5.242030\n",
      "44    4.711175\n",
      "86    5.079078\n",
      "89    3.489503\n",
      "39    6.647218\n",
      "Name: 4.4330699, dtype: float64\n",
      "R^2 score for target 4.4330699: -0.09616581976098515\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 5.010430003: (108,)\n",
      "First few values of y_train_target for target 5.010430003: 49    4.268183\n",
      "44    4.622649\n",
      "86    5.039226\n",
      "89    4.667650\n",
      "39    6.398213\n",
      "Name: 5.010430003, dtype: float64\n",
      "Error: Invalid data found. Skipping target 5.010430003\n",
      "Shape of X_train: (108, 2)\n",
      "Shape of y_train for target 5.616075934: (108,)\n",
      "First few values of y_train_target for target 5.616075934: 49    6.172896\n",
      "44    5.410068\n",
      "86    6.241098\n",
      "89    4.658240\n",
      "39    6.492445\n",
      "Name: 5.616075934, dtype: float64\n",
      "R^2 score for target 5.616075934: -0.04411009259775511\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 5.601585674: (108,)\n",
      "First few values of y_train_target for target 5.601585674: 49    5.736839\n",
      "44    4.666732\n",
      "86    5.078528\n",
      "89    3.824190\n",
      "39    6.140327\n",
      "Name: 5.601585674, dtype: float64\n",
      "Error: Invalid data found. Skipping target 5.601585674\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 5.426861477: (108,)\n",
      "First few values of y_train_target for target 5.426861477: 49    6.597411\n",
      "44    5.671484\n",
      "86    5.577104\n",
      "89    4.990368\n",
      "39    6.392497\n",
      "Name: 5.426861477, dtype: float64\n",
      "Error: Invalid data found. Skipping target 5.426861477\n",
      "Shape of X_train: (108, 3)\n",
      "Shape of y_train for target 6.062172752: (108,)\n",
      "First few values of y_train_target for target 6.062172752: 49    6.299461\n",
      "44    4.570863\n",
      "86    5.547265\n",
      "89    5.862804\n",
      "39    6.418174\n",
      "Name: 6.062172752, dtype: float64\n",
      "R^2 score for target 6.062172752: -0.1774807872819626\n",
      "Shape of X_train: (108, 3)\n",
      "Shape of y_train for target 5.016286087: (108,)\n",
      "First few values of y_train_target for target 5.016286087: 49    4.924798\n",
      "44    4.368588\n",
      "86    4.582651\n",
      "89    4.270317\n",
      "39    4.641777\n",
      "Name: 5.016286087, dtype: float64\n",
      "R^2 score for target 5.016286087: -0.7043527426192056\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 3.33245849: (108,)\n",
      "First few values of y_train_target for target 3.33245849: 49    4.204325\n",
      "44    4.070676\n",
      "86    2.515332\n",
      "89    4.709002\n",
      "39    5.768629\n",
      "Name: 3.33245849, dtype: float64\n",
      "Error: Invalid data found. Skipping target 3.33245849\n",
      "Shape of X_train: (108, 2)\n",
      "Shape of y_train for target 6.500328772: (108,)\n",
      "First few values of y_train_target for target 6.500328772: 49    5.465457\n",
      "44    5.092379\n",
      "86    5.713781\n",
      "89    4.933547\n",
      "39    6.611584\n",
      "Name: 6.500328772, dtype: float64\n",
      "R^2 score for target 6.500328772: -0.010232771502759919\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 4.791549548: (108,)\n",
      "First few values of y_train_target for target 4.791549548: 49    4.839598\n",
      "44    5.547229\n",
      "86    5.055448\n",
      "89    6.260426\n",
      "39    6.421610\n",
      "Name: 4.791549548, dtype: float64\n",
      "Error: Invalid data found. Skipping target 4.791549548\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 5.621230924: (108,)\n",
      "First few values of y_train_target for target 5.621230924: 49    6.116738\n",
      "44    4.736510\n",
      "86    4.997352\n",
      "89    3.170992\n",
      "39    6.279074\n",
      "Name: 5.621230924, dtype: float64\n",
      "Error: Invalid data found. Skipping target 5.621230924\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 3.912198868: (108,)\n",
      "First few values of y_train_target for target 3.912198868: 49    4.435470\n",
      "44    3.982634\n",
      "86    5.126957\n",
      "89    3.146498\n",
      "39    6.026201\n",
      "Name: 3.912198868, dtype: float64\n",
      "Error: Invalid data found. Skipping target 3.912198868\n",
      "Shape of X_train: (108, 4)\n",
      "Shape of y_train for target 4.476537266: (108,)\n",
      "First few values of y_train_target for target 4.476537266: 49    5.756203\n",
      "44    5.281840\n",
      "86    4.776835\n",
      "89    4.017484\n",
      "39    6.108967\n",
      "Name: 4.476537266, dtype: float64\n",
      "R^2 score for target 4.476537266: -0.8875040879571978\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 5.521214555: (108,)\n",
      "First few values of y_train_target for target 5.521214555: 49    6.139017\n",
      "44    5.319264\n",
      "86    4.925286\n",
      "89    4.257064\n",
      "39    5.989828\n",
      "Name: 5.521214555, dtype: float64\n",
      "Error: Invalid data found. Skipping target 5.521214555\n",
      "Shape of X_train: (108, 6)\n",
      "Shape of y_train for target 5.549828722: (108,)\n",
      "First few values of y_train_target for target 5.549828722: 49    5.933635\n",
      "44    5.144276\n",
      "86    5.185350\n",
      "89    4.877960\n",
      "39    6.728405\n",
      "Name: 5.549828722, dtype: float64\n",
      "R^2 score for target 5.549828722: -0.3437990525667034\n",
      "Shape of X_train: (108, 4)\n",
      "Shape of y_train for target 6.014960324: (108,)\n",
      "First few values of y_train_target for target 6.014960324: 49    5.801407\n",
      "44    5.751991\n",
      "86    5.903406\n",
      "89    5.360826\n",
      "39    6.068455\n",
      "Name: 6.014960324, dtype: float64\n",
      "R^2 score for target 6.014960324: -0.25084307439237086\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 4.923550435: (108,)\n",
      "First few values of y_train_target for target 4.923550435: 49    6.247816\n",
      "44    4.637788\n",
      "86    4.874192\n",
      "89    2.820304\n",
      "39    6.537314\n",
      "Name: 4.923550435, dtype: float64\n",
      "Error: Invalid data found. Skipping target 4.923550435\n",
      "Shape of X_train: (108, 0)\n",
      "Shape of y_train for target 92.22523191: (108,)\n",
      "First few values of y_train_target for target 92.22523191: 49    100.018057\n",
      "44     88.305343\n",
      "86     91.241561\n",
      "89     79.033872\n",
      "39    112.251688\n",
      "Name: 92.22523191, dtype: float64\n",
      "Error: Invalid data found. Skipping target 92.22523191\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFwe\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data, ignoring the first row and first column\n",
    "x_df = pd.read_csv(x_data, skiprows=1).iloc[:, 1:]  # Exclude first column (P83-like identifiers)\n",
    "y_df = pd.read_csv(y_data, skiprows=1).iloc[:, 1:]\n",
    "\n",
    "# Ensure all values in the feature columns are numeric\n",
    "x_df = x_df.apply(pd.to_numeric, errors='coerce')  # Coerce invalid values to NaN\n",
    "\n",
    "# Remove rows with NaN values (if any after coercion)\n",
    "x_df.dropna(inplace=True)\n",
    "y_df = y_df.iloc[:len(x_df)]  # Ensure y_df has the same number of rows\n",
    "\n",
    "# Optional: If you need to encode categorical labels (for example, if they are not already numeric)\n",
    "if x_df.select_dtypes(include=['object']).shape[1] > 0:\n",
    "    label_encoder = LabelEncoder()\n",
    "    x_df = x_df.apply(label_encoder.fit_transform)  # Convert any categorical columns to numbers\n",
    "\n",
    "# Set up the regressor (RandomForestRegressor for continuous target)\n",
    "regressor = RandomForestRegressor(random_state=20, n_estimators=100, max_depth=7, criterion='squared_error')\n",
    "\n",
    "# Feature selection and model training\n",
    "for i in range(len(y_df.columns)):\n",
    "    selector = SelectFwe(alpha=0.4)\n",
    "    \n",
    "    # Fit the selector to the data\n",
    "    X_new = selector.fit_transform(x_df, y_df.iloc[:, i])  # Use iloc to select the correct column\n",
    "    X = pd.DataFrame(X_new)\n",
    "\n",
    "    # Split into training and testing datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_df, test_size=0.2, random_state=20)\n",
    "    \n",
    "    # Optional: Drop highly correlated features\n",
    "    corr_features = correlation(X_train, 0.8)\n",
    "    X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "    # Check if X_train and y_train have valid shapes and data\n",
    "    print(f\"Shape of X_train: {X_train.shape}\")\n",
    "    print(f\"Shape of y_train for target {y_df.columns[i]}: {y_train.iloc[:, i].shape}\")\n",
    "    print(f\"First few values of y_train_target for target {y_df.columns[i]}: {y_train.iloc[:, i].head()}\")\n",
    "\n",
    "    # Ensure y_train is a valid series\n",
    "    y_train_target = y_train.iloc[:, i] if isinstance(y_train.iloc[:, i], pd.Series) else y_train.iloc[:, i].squeeze()\n",
    "\n",
    "    # Check for empty or invalid data\n",
    "    if X_train.empty or y_train_target.empty or X_train.isnull().any().any() or y_train_target.isnull().any():\n",
    "        print(f\"Error: Invalid data found. Skipping target {y_df.columns[i]}\")\n",
    "        continue  # Skip this target and proceed to the next one\n",
    "\n",
    "    # Fit the regressor and predict\n",
    "    regressor.fit(X_train, y_train_target)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "    \n",
    "    # Evaluate the model - Use appropriate regression metrics\n",
    "    print(f\"R^2 score for target {y_df.columns[i]}: {regressor.score(X_test, y_test.iloc[:, i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features selected for target column 4.414892172\n",
      "No features selected for target column 4.4330699\n",
      "No features selected for target column 5.010430003\n",
      "No features selected for target column 5.616075934\n",
      "No features selected for target column 5.601585674\n",
      "No features selected for target column 5.426861477\n",
      "Features selected for target 6.062172752: 1\n",
      "X_train shape after correlation filter for target 6.062172752: (108, 1)\n",
      "y_train shape for target 6.062172752: (108,)\n",
      "Accuracy for 6.062172752: 0.6428571428571429\n",
      "Features selected for target 5.016286087: 1\n",
      "X_train shape after correlation filter for target 5.016286087: (108, 1)\n",
      "y_train shape for target 5.016286087: (108,)\n",
      "Accuracy for 5.016286087: 0.4642857142857143\n",
      "No features selected for target column 3.33245849\n",
      "No features selected for target column 6.500328772\n",
      "No features selected for target column 4.791549548\n",
      "No features selected for target column 5.621230924\n",
      "No features selected for target column 3.912198868\n",
      "No features selected for target column 4.476537266\n",
      "No features selected for target column 5.521214555\n",
      "Features selected for target 5.549828722: 1\n",
      "X_train shape after correlation filter for target 5.549828722: (108, 1)\n",
      "y_train shape for target 5.549828722: (108,)\n",
      "Accuracy for 5.549828722: 0.5357142857142857\n",
      "No features selected for target column 6.014960324\n",
      "No features selected for target column 4.923550435\n",
      "No features selected for target column 92.22523191\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFwe\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the data, ignoring the first row and first column\n",
    "x_df = pd.read_csv(x_data, skiprows=1).iloc[:, 1:]\n",
    "y_df = pd.read_csv(y_data, skiprows=1).iloc[:, 1:]\n",
    "\n",
    "# Ensure all values are numeric, coercing errors, and drop any columns with NaN values from coercion\n",
    "x_df = x_df.apply(pd.to_numeric, errors='coerce').dropna(axis=1)\n",
    "y_df = y_df.apply(pd.to_numeric, errors='coerce').dropna(axis=1)\n",
    "\n",
    "# Ensure both x_df and y_df have the same number of rows\n",
    "min_rows = min(len(x_df), len(y_df))\n",
    "x_df = x_df.iloc[:min_rows, :]\n",
    "y_df = y_df.iloc[:min_rows, :]\n",
    "\n",
    "# Convert continuous target values to discrete categories\n",
    "y_df = y_df.apply(lambda col: pd.cut(col, bins=3, labels=[0, 1, 2]))\n",
    "\n",
    "# Set a valid alpha value for SelectFwe\n",
    "alpha_value = 0.1  # Adjust alpha for a less strict selection criterion\n",
    "\n",
    "# Define the classifier\n",
    "clf = RandomForestClassifier(random_state=20, max_features=10, n_estimators=100, max_depth=7, criterion='entropy')\n",
    "\n",
    "# Loop through each target column in y_df\n",
    "for i in range(len(y_df.columns)):\n",
    "    selector = SelectFwe(alpha=alpha_value)\n",
    "    X_new = selector.fit_transform(x_df, y_df[y_df.columns[i]])\n",
    "\n",
    "    # Check if X_new is empty after SelectFwe\n",
    "    if X_new.shape[1] == 0:\n",
    "        print(f\"No features selected for target column {y_df.columns[i]}\")\n",
    "        continue\n",
    "\n",
    "    X = pd.DataFrame(X_new)\n",
    "\n",
    "    # Print the number of features selected\n",
    "    print(f\"Features selected for target {y_df.columns[i]}: {X.shape[1]}\")\n",
    "\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_df[y_df.columns[i]], test_size=0.2, random_state=20)\n",
    "\n",
    "    # Correlation feature elimination (assuming `correlation` is defined elsewhere)\n",
    "    corr_features = correlation(X_train, 0.8)\n",
    "    X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "    # Check shapes after dropping correlated features\n",
    "    print(f\"X_train shape after correlation filter for target {y_df.columns[i]}: {X_train.shape}\")\n",
    "    print(f\"y_train shape for target {y_df.columns[i]}: {y_train.shape}\")\n",
    "\n",
    "    # Ensure X_train and y_train are not empty\n",
    "    if X_train.empty or y_train.empty:\n",
    "        print(f\"Empty training set for target {y_df.columns[i]} after filtering. Skipping this target.\")\n",
    "        continue\n",
    "\n",
    "    # Train and test the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "\n",
    "    # Print accuracy score\n",
    "    print(f\"Accuracy for {y_df.columns[i]}: {accuracy_score(y_test, y_predict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 4.414892172: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 4.414892172 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.414892172 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.414892172 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 4.414892172: 0.0\n",
      "Target 4.4330699: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 4.4330699 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.4330699 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.4330699 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 4.4330699: 0.0\n",
      "Target 5.010430003: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 5.010430003 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.010430003 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.010430003 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 5.010430003: 0.0\n",
      "Target 5.616075934: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 5.616075934 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.616075934 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.616075934 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 5.616075934: 0.0\n",
      "Target 5.601585674: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 5.601585674 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.601585674 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.601585674 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 5.601585674: 0.0\n",
      "Target 5.426861477: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 5.426861477 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.426861477 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.426861477 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 5.426861477: 0.0\n",
      "Target 6.062172752: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 6.062172752 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 6.062172752 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 6.062172752 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 6.062172752: 0.0\n",
      "Target 5.016286087: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 5.016286087 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.016286087 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.016286087 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 5.016286087: 0.0\n",
      "Target 3.33245849: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 3.33245849 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 3.33245849 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 3.33245849 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 3.33245849: 0.0\n",
      "Target 6.500328772: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 6.500328772 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 6.500328772 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 6.500328772 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 6.500328772: 0.0\n",
      "Target 4.791549548: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 4.791549548 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.791549548 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.791549548 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 4.791549548: 0.0\n",
      "Target 5.621230924: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 5.621230924 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.621230924 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.621230924 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 5.621230924: 0.0\n",
      "Target 3.912198868: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 3.912198868 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 3.912198868 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 3.912198868 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 3.912198868: 0.0\n",
      "Target 4.476537266: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 4.476537266 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.476537266 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.476537266 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 4.476537266: 0.0\n",
      "Target 5.521214555: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 5.521214555 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.521214555 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.521214555 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 5.521214555: 0.0\n",
      "Target 5.549828722: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 5.549828722 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.549828722 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 5.549828722 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 5.549828722: 0.0\n",
      "Target 6.014960324: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 6.014960324 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 6.014960324 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 6.014960324 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 6.014960324: 0.0\n",
      "Target 4.923550435: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 4.923550435 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.923550435 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 4.923550435 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 4.923550435: 0.0\n",
      "Target 92.22523191: Number of features after SelectFdr: 0\n",
      "Warning: X_train is empty for target 92.22523191 at fold 1. Skipping this fold.\n",
      "Warning: X_train is empty for target 92.22523191 at fold 2. Skipping this fold.\n",
      "Warning: X_train is empty for target 92.22523191 at fold 3. Skipping this fold.\n",
      "Average accuracy for target column 92.22523191: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFdr\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Loop through each target column in y_df\n",
    "for i in range(len(y_df.columns)):\n",
    "    selector = SelectFdr(chi2, alpha=0.9)\n",
    "    X_new = selector.fit_transform(x_df_scaled, y_df[y_df.columns[i]])\n",
    "    X = pd.DataFrame(X_new)\n",
    "\n",
    "    # Debugging: Check the number of features after selection\n",
    "    print(f\"Target {y_df.columns[i]}: Number of features after SelectFdr: {X.shape[1]}\")\n",
    "\n",
    "    summ = 0\n",
    "    count = 0\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        count += 1\n",
    "        X_train, X_test = X.loc[train_index], X.loc[val_index]\n",
    "        y_train, y_test = y_df.iloc[train_index, i], y_df.iloc[val_index, i]\n",
    "\n",
    "        # Debugging: Check if X_train is empty before fitting the scaler\n",
    "        if X_train.empty:\n",
    "            print(f\"Warning: X_train is empty for target {y_df.columns[i]} at fold {count}. Skipping this fold.\")\n",
    "            continue\n",
    "\n",
    "        # Standard scaling for the features\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Convert back to DataFrame\n",
    "        X_train = pd.DataFrame(X_train)\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "\n",
    "        # Drop correlated features\n",
    "        corr_features = correlation(X_train, 0.8)  # Consider lowering the threshold\n",
    "        print(f\"Target {y_df.columns[i]}: Dropped features due to correlation: {len(corr_features)}\")\n",
    "        \n",
    "        X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "        X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "        # Check if X_train is empty after dropping correlated features\n",
    "        if X_train.empty:\n",
    "            print(f\"Warning: X_train is empty after dropping correlated features for target {y_df.columns[i]} at fold {count}. Skipping this fold.\")\n",
    "            continue\n",
    "\n",
    "        # Fit the classifier and make predictions\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        summ += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print average accuracy\n",
    "    print(f\"Average accuracy for target column {y_df.columns[i]}: {summ / count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(m,X,y):\n",
    "    yhat = m.predict(X)\n",
    "    print(yhat)\n",
    "    SS_Residual = sum((y-yhat)**2)\n",
    "    SS_Total = sum((y-np.mean(y))**2)\n",
    "    r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "    adj_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
    "    return r_squared,adj_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.297315623    146.782207\n",
      "dtype: float64 0    143.788368\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.10622414    141.625051\n",
      "dtype: float64 0    133.671302\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.33300425    139.27781\n",
      "dtype: float64 0    142.823183\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.541379781    153.314605\n",
      "dtype: float64 0    150.476389\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.043890154    138.863209\n",
      "dtype: float64 0    135.271895\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.866118592    152.471376\n",
      "dtype: float64 0    156.830639\n",
      "dtype: float64\n",
      "-------------------\n",
      "3.57615974    146.453654\n",
      "dtype: float64 0    149.364771\n",
      "dtype: float64\n",
      "-------------------\n",
      "4.865589795    131.388855\n",
      "dtype: float64 0    129.592713\n",
      "dtype: float64\n",
      "-------------------\n",
      "3.771664731    118.321698\n",
      "dtype: float64 0    122.052537\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.25478356    147.930427\n",
      "dtype: float64 0    154.315796\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.800467905    156.979808\n",
      "dtype: float64 0    156.986392\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.147909377    139.6206\n",
      "dtype: float64 0    134.532393\n",
      "dtype: float64\n",
      "-------------------\n",
      "4.891580046    131.846434\n",
      "dtype: float64 0    136.009724\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.351075433    153.838155\n",
      "dtype: float64 0    151.497499\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.350759594    153.804237\n",
      "dtype: float64 0    150.888636\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.845226374    161.974189\n",
      "dtype: float64 0    154.488265\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.610512744    166.685379\n",
      "dtype: float64 0    163.743305\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.477533668    149.74487\n",
      "dtype: float64 0    139.727909\n",
      "dtype: float64\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "param_grid = {\n",
    "    'C': [0.5, 1.0, 2.0],\n",
    "    'epsilon': [0.1,0.2,0.5, 0.9],\n",
    "    \n",
    "#     'min_samples_split': [8, 10, 12],\n",
    "#      'n_estimators': [10, 20, 100, 200]\n",
    "}\n",
    "# Create a based model\n",
    "clf = dtree1 = DecisionTreeRegressor(max_depth=2)\n",
    "# Instantiate the grid search model\n",
    "#clf = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = 6, verbose = 2)\n",
    "#clf = RandomForestClassifier(random_state=20, max_features=10, n_estimators= 100, max_depth=7, criterion='entropy')\n",
    "X = x_df\n",
    "for i in range(len(y_df.columns)):\n",
    "    \n",
    "#     reg = LassoCV()\n",
    "#     reg.fit(x_df, y_df[y_df.columns[i:i+1]])\n",
    "#     print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "#     print(\"Best score using built-in LassoCV: %f\" %reg.score(x_df, y_df[y_df.columns[i:i+1]]))\n",
    "#     print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "#     coef = pd.Series(reg.coef_, index = x_df.columns)\n",
    "#     imp_coef = coef.sort_values()\n",
    "#     print(imp_coef)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_df,y_df[y_df.columns[i:i+1]], test_size=0.2)\n",
    "    \n",
    "    scaler = StandardScaler()  # doctest: +SKIP\n",
    "    scaler.fit(X_train)  # doctest: +SKIP\n",
    "    X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "    X_test = scaler.transform(X_test) \n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "#     print(y_predict)\n",
    "#     print(y_test)\n",
    "    print(y_test.sum(), y_predict.sum())\n",
    "    #print(r2_score(y_test, y_pred))\n",
    "    print(\"-------------------\")\n",
    "    \n",
    "#     macro_roc_auc_ovo = multiclass_roc_auc_score(y_test,y_predict)\n",
    "#     print(macro_roc_auc_ovo)\n",
    "   \n",
    "#     print(clf.score(X_test,y_test))\n",
    "#     x_df = X\n",
    "#     cols = list(x_df.columns)\n",
    "#     model = LinearRegression()\n",
    "#     #Initializing RFE model\n",
    "#     rfe = RFE(model, 10)             \n",
    "#     #Transforming data using RFE\n",
    "#     X_rfe = rfe.fit_transform(x_df,y_df[y_df.columns[i:i+1]])  \n",
    "#     #Fitting the data to model\n",
    "#     model.fit(X_rfe,y_df[y_df.columns[i:i+1]])              \n",
    "#     temp = pd.Series(rfe.support_,index = cols)\n",
    "#     selected_features_rfe = temp[temp==True].index\n",
    "#     print(selected_features_rfe)\n",
    "#     for i in x_df.columns:\n",
    "#         if i not in selected_features_rfe:\n",
    "#             x_df = x_df.drop(i, axis=1)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(x_df,y_df[y_df.columns[i:i+1]], test_size=0.2)\n",
    "#     scaler = StandardScaler()  # doctest: +SKIP\n",
    "#     scaler.fit(X_train)  # doctest: +SKIP\n",
    "#     X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "#     X_test = scaler.transform(X_test) \n",
    "#     X_train = pd.DataFrame(X_train)\n",
    "#     X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "#     clf.fit(X_train, y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     y_predict = pd.DataFrame(y_pred)\n",
    "    \n",
    "# #     macro_roc_auc_ovo = multiclass_roc_auc_score(y_test,y_predict)\n",
    "# #     print(macro_roc_auc_ovo)\n",
    "#     #print(accuracy_score(y_test,y_predict))\n",
    "#     print(clf.score(X_test,y_test))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.297315623</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.355869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>5.293564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.190017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>5.954057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>4.727263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.538979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.038526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>5.415966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>4.760002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.236546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>4.864386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.608315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>5.846003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.725115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>4.642314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.784742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>5.382496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.457670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>5.157982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>5.319215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>4.581633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>5.770041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.771733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>4.057952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>4.738970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>4.789387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>4.865379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>5.380115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     5.297315623\n",
       "70      5.355869\n",
       "89      5.293564\n",
       "20      5.190017\n",
       "64      5.954057\n",
       "54      4.727263\n",
       "100     5.538979\n",
       "8       5.038526\n",
       "107     5.415966\n",
       "121     4.760002\n",
       "14      4.236546\n",
       "53      4.864386\n",
       "120     3.608315\n",
       "63      5.846003\n",
       "6       4.725115\n",
       "59      4.642314\n",
       "130     5.784742\n",
       "94      5.382496\n",
       "2       5.457670\n",
       "58      5.157982\n",
       "74      5.319215\n",
       "125     4.581633\n",
       "104     5.770041\n",
       "17      5.771733\n",
       "105     4.057952\n",
       "47      4.738970\n",
       "61      4.789387\n",
       "43      4.865379\n",
       "129     5.380115"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.70        86\n",
      "           1       0.71      0.58      0.64        86\n",
      "\n",
      "    accuracy                           0.67       172\n",
      "   macro avg       0.68      0.67      0.67       172\n",
      "weighted avg       0.68      0.67      0.67       172\n",
      "\n",
      "[1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1]\n",
      "\n",
      "Classification Report for Testing Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.50      0.31         4\n",
      "           1       0.89      0.71      0.79        24\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.56      0.60      0.55        28\n",
      "weighted avg       0.80      0.68      0.72        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_csv('F:/Video_Interview_Bots/Video_Interview_Bot/Emotion_Detection_FER/Classification/Input_Data/Video_features_combined_average_with_not_stressed_column - Sheet1 (1).csv')\n",
    "\n",
    "# Binarize the 'Not Stressed' column\n",
    "threshold = 5\n",
    "data['Not Stressed Binary'] = (data['Not Stressed'] > threshold).astype(int)\n",
    "\n",
    "# Prepare the features and target variable\n",
    "ids = data['ID']\n",
    "X = data.drop(columns=['ID', 'Not Stressed', 'Not Stressed Binary'])  # Features\n",
    "y = data['Not Stressed Binary']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, train_ids, test_ids = train_test_split(X, y, ids, test_size=0.2, random_state=42)\n",
    "y_lst = []\n",
    "y_lst.append(y_test)\n",
    "\n",
    "# Apply SMOTE over-sampling to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(solver='newton-cg')\n",
    "model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Make predictions and get probabilities for the training set\n",
    "train_predictions = model.predict(X_train_scaled)\n",
    "# train_ids = data['ID'].iloc[X_train.index]\n",
    "# print(train_predictions)\n",
    "train_probabilities = model.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "# Print classification report for training set\n",
    "print(\"Classification Report for Training Set:\")\n",
    "print(classification_report(y_train_resampled, train_predictions))\n",
    "\n",
    "# Make predictions and get probabilities for the testing set\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "# test_ids = data['ID'].iloc[X_test.index]\n",
    "print(test_predictions)\n",
    "test_probabilities = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Print classification report for testing set\n",
    "print(\"\\nClassification Report for Testing Set:\")\n",
    "print(classification_report(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1618\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\series.py:971\u001b[0m, in \u001b[0;36mSeries._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 971\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\series.py:956\u001b[0m, in \u001b[0;36mSeries.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 956\u001b[0m new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mtake(indices)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:1090\u001b[0m, in \u001b[0;36mIndex.take\u001b[1;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m-> 1090\u001b[0m     taken \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_na_value\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# algos.take passes 'axis' keyword which not all EAs accept\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\algorithms.py:1258\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;66;03m# NumPy style\u001b[39;00m\n\u001b[1;32m-> 1258\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mIndexError\u001b[0m: index 110 is out of bounds for axis 0 with size 110",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Optionally, save results to CSV files\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtrain_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Label\u001b[39m\u001b[38;5;124m'\u001b[39m: train_predictions,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbability of Not Stressed\u001b[39m\u001b[38;5;124m'\u001b[39m: train_probabilities,\n\u001b[0;32m      6\u001b[0m })\n\u001b[0;32m      7\u001b[0m train_output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF:/Video_Interview_Bots/Video_Interview_Bot/Emotion_Detection_FER/Classification/Output/average_training_predicted_labels_and_probabilities_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m train_results\u001b[38;5;241m.\u001b[39mto_csv(train_output_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1645\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> 1647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1651\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1621\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n\u001b[1;32m-> 1621\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Optionally, save results to CSV files\n",
    "train_results = pd.DataFrame({\n",
    "    'ID': train_ids.iloc[np.arange(len(X_train_resampled))],\n",
    "    'Predicted Label': train_predictions,\n",
    "    'Probability of Not Stressed': train_probabilities,\n",
    "})\n",
    "train_output_file_path = 'F:/Video_Interview_Bots/Video_Interview_Bot/Emotion_Detection_FER/Classification/Output/average_training_predicted_labels_and_probabilities_1.csv'\n",
    "train_results.to_csv(train_output_file_path, index=False)\n",
    "print(f\"Training output saved to {train_output_file_path}\")\n",
    "\n",
    "test_results = pd.DataFrame({\n",
    "    'ID': test_ids.iloc[np.arange(len(X_test))],\n",
    "    'Predicted Label': test_predictions,\n",
    "    'Probability of Not Stressed': test_probabilities,\n",
    "})\n",
    "test_output_file_path = 'F:/Video_Interview_Bots/Video_Interview_Bot/Emotion_Detection_FER/Classification/Output/average_testing_predicted_labels_and_probabilities_1.csv'\n",
    "test_results.to_csv(test_output_file_path, index=False)\n",
    "print(f\"Testing output saved to {test_output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1618\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\series.py:971\u001b[0m, in \u001b[0;36mSeries._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 971\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\series.py:956\u001b[0m, in \u001b[0;36mSeries.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 956\u001b[0m new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mtake(indices)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:1090\u001b[0m, in \u001b[0;36mIndex.take\u001b[1;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m-> 1090\u001b[0m     taken \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_na_value\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# algos.take passes 'axis' keyword which not all EAs accept\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\algorithms.py:1258\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;66;03m# NumPy style\u001b[39;00m\n\u001b[1;32m-> 1258\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mIndexError\u001b[0m: index 110 is out of bounds for axis 0 with size 110",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m train_probabilities \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_train_scaled)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Save training results to a CSV file\u001b[39;00m\n\u001b[0;32m     42\u001b[0m train_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtrain_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,  \u001b[38;5;66;03m# Use resampled indices for IDs\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Label\u001b[39m\u001b[38;5;124m'\u001b[39m: train_predictions,\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbability of Not Stressed\u001b[39m\u001b[38;5;124m'\u001b[39m: train_probabilities,\n\u001b[0;32m     46\u001b[0m })\n\u001b[0;32m     47\u001b[0m train_output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF:/Video_Interview_Bots/Video_Interview_Bot/Emotion_Detection_FER/Classification/Output/training_predicted_labels_and_probabilities.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     48\u001b[0m train_results\u001b[38;5;241m.\u001b[39mto_csv(train_output_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1645\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> 1647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1651\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1621\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n\u001b[1;32m-> 1621\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_csv('F:/Video_Interview_Bots/Video_Interview_Bot/Emotion_Detection_FER/Classification/Input_Data/Video_features_combined_most_frequent_with_not_stressed_column - Sheet1.csv')\n",
    "\n",
    "# Binarize the 'Not Stressed' column\n",
    "threshold = 5\n",
    "df['Not Stressed Binary'] = (df['Not Stressed'] > threshold).astype(int)\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df.drop(columns=['ID', 'Not Stressed', 'Not Stressed Binary'])  # Features\n",
    "y = df['Not Stressed Binary']  # Target variable\n",
    "ids = df['ID']  # Store IDs separately\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, train_ids, test_ids = train_test_split(X, y, ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE for handling class imbalance in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(solver='newton-cg', class_weight='balanced')\n",
    "model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Make predictions and get probabilities for the training set\n",
    "train_predictions = model.predict(X_train_scaled)\n",
    "train_probabilities = model.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "# Save training results to a CSV file\n",
    "train_results = pd.DataFrame({\n",
    "    'ID': train_ids.iloc[np.arange(len(X_train_resampled))],  # Use resampled indices for IDs\n",
    "    'Predicted Label': train_predictions,\n",
    "    'Probability of Not Stressed': train_probabilities,\n",
    "})\n",
    "train_output_file_path = 'F:/Video_Interview_Bots/Video_Interview_Bot/Emotion_Detection_FER/Classification/Output/training_predicted_labels_and_probabilities.csv'\n",
    "train_results.to_csv(train_output_file_path, index=False)\n",
    "print(f\"Training output saved to {train_output_file_path}\")\n",
    "\n",
    "# Make predictions and get probabilities for the testing set\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "test_probabilities = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Save testing results to a CSV file\n",
    "test_results = pd.DataFrame({\n",
    "    'ID': test_ids.iloc[np.arange(len(X_test))],  # Use original indices for IDs\n",
    "    'Predicted Label': test_predictions,\n",
    "    'Probability of Not Stressed': test_probabilities,\n",
    "})\n",
    "test_output_file_path = 'F:/Video_Interview_Bots/Video_Interview_Bot/Emotion_Detection_FER/Classification/Output/testing_predicted_labels_and_probabilities.csv'\n",
    "test_results.to_csv(test_output_file_path, index=False)\n",
    "print(f\"Testing output saved to {test_output_file_path}\")\n",
    "\n",
    "# Print classification report for training set\n",
    "print(\"\\nClassification Report for Training data:\")\n",
    "print(classification_report(y_train_resampled, train_predictions))\n",
    "\n",
    "# Print classification report for testing set\n",
    "print(\"\\nClassification Report for Testing data:\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
